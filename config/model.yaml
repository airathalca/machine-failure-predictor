optuna:
  n_trials: 15  # Number of trials for Optuna to run
  timeout: 600  # Maximum time (in seconds) for the optimization
  direction: maximize  # Direction of optimization (maximize or minimize)
  study_name: model_tuning  # Name of the Optuna study

models:
  xgb:
    class: XGBClassifier
    module: xgboost
    params:
      objective: binary:logistic
      eval_metric: auc
      random_state: 42
    search_space:
      n_estimators:
        type: int
        low: 100
        high: 500
      learning_rate:
        type: float
        low: 0.001
        high: 0.3
        log: True  # Use loguniform distribution
      max_depth:
        type: int
        low: 3
        high: 15
      subsample:
        type: float
        low: 0.5
        high: 1.0
      colsample_bytree:
        type: float
        low: 0.5
        high: 1.0

  lgbm:
    class: LGBMClassifier
    module: lightgbm
    params:
      metric: auc
      verbosity: -1
      random_state: 42
      is_unbalance: True
    search_space:
      n_estimators:
        type: int
        low: 100
        high: 500
      learning_rate:
        type: float
        low: 0.001
        high: 0.3
        log: True  # Use loguniform distribution
      max_depth:
        type: int
        low: 3
        high: 15
      num_leaves:
        type: int
        low: 10
        high: 100
      subsample:
        type: float
        low: 0.5
        high: 1.0
      colsample_bytree:
        type: float
        low: 0.5
        high: 1.0

  balanced_rf:
    class: BalancedRandomForestClassifier
    module: imblearn.ensemble
    params:
      random_state: 42
    search_space:
      n_estimators:
        type: int
        low: 100
        high: 500
      max_depth:
        type: categorical
        choices: [10, None]
      min_samples_split:
        type: int
        low: 2
        high: 5
      min_samples_leaf:
        type: int
        low: 1
        high: 5
      max_features:
        type: categorical
        choices: [sqrt, log2, None]

voting_classifier:
  class: VotingClassifier
  module: sklearn.ensemble
  params:
    voting: soft
    weights: [1, 1, 1]  # Equal weights for all models